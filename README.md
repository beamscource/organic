# Phase 1:

scraping beatbox videos from YT
https://github.com/marcosschroh/youtube-audio-downloader/blob/master/sound_downloader/downloader.py

https://www.geeksforgeeks.org/youtube-mediaaudio-download-using-python-pafy/

https://github.com/carlthome/audio-scraper

**Define the data set**

sound classes in beat box: 50 to 120

see https://www.reddit.com/r/beatbox/comments/bfrfrl/here_it_is_a_complete_list_of_all_sounds_in/

prepare a dataset with sounds for phase 2/3 - label the sound clips wrt to their sound category

classification CNN+LSTM model for beatbox sounds

https://hackernoon.com/intro-to-audio-analysis-recognizing-sounds-using-machine-learning-qy2r3ufl

https://www.nature.com/articles/s41598-021-96446-w https://www.nature.com/articles/s41598-019-48909-4

https://towardsdatascience.com/audio-deep-learning-made-simple-sound-classification-step-by-step-cebc936bbe5

https://towardsdatascience.com/real-time-sound-event-classification-83e892cf187e

use case 1: beatbox analytics for different beat boxers (Are there more instance of X in routines of beatboxer A vs beatboxer B?)
use case 2: semi-supervised training for new data

# Phase 2:

generative beatbox sounds GAN/VAE model
train a generative model
https://medium.com/@rachelchen_49210/generating-ambient-noise-from-wavenet-95aa7f0a8f77

https://towardsdatascience.com/neuralfunk-combining-deep-learning-with-sound-design-91935759d628

https://magenta.tensorflow.org/nsynth

https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio

# Phase 3: maybe

app using a style transfer model
https://arxiv.org/abs/2207.08759

https://github.com/inzva/Audio-Style-Transfer
